{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\Xv}{\\mathbf{X}}\n",
    "\\newcommand{\\yv}{\\mathbf{y}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\av}{\\mathbf{a}}\n",
    "\\newcommand{\\Wv}{\\mathbf{W}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "\\newcommand{\\tv}{\\mathbf{t}}\n",
    "\\newcommand{\\Tv}{\\mathbf{T}}\n",
    "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Fixed Nonlinear Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models we have been buildling are linear in the parameters $\\wv$\n",
    "and linear in the attributes (features) of the samples.  We can make\n",
    "models that are nonlinear in the attributes by adding nonlinear\n",
    "functions of the original features.  \n",
    "\n",
    "Say we have a single feature for each sample.  Our data matrix is\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    " X &= \\begin{bmatrix}\n",
    "       x_0\\\\\n",
    "       x_1\\\\\n",
    "       \\vdots \\\\\n",
    "       x_N\n",
    "       \\end{bmatrix}\n",
    "\\end{alignat*}\n",
    "$$\n",
    "We can add other powers of each $x$ value, say up to the fourth power.\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    " X &= \\begin{bmatrix}\n",
    "       x_0 & x_0^2 & x_0^3 & x_0^4\\\\\n",
    "       x_1 & x_1^2 & x_1^3 & x_1^4\\\\\n",
    "       \\vdots \\\\\n",
    "       x_N & x_N^2 & x_N^3 & x_N^4\\\\\n",
    "       \\end{bmatrix}\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "This is simple to do in python.\n",
    "\n",
    "    X = np.hstack((X, X**2, X**3, X**4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of these powers of $x$ are useful?  Looking at the magnitudes of\n",
    "the weights is helpful, as long as the input features are\n",
    "standardized.  We can do more than this, though.  If we build multiple\n",
    "models from multiple bootstrap samples of the training data, we can\n",
    "compute confidence intervals of the weight values.  If zero is\n",
    "not included in the range of\n",
    "weight values specified by a weight's 90% lower and\n",
    "upper confidencce limit, then we can say that we are 90% certain that\n",
    "the value of this weight is not zero.  If the range does include zero,\n",
    "the corresponding feature is probably one that is not useful.\n",
    "\n",
    "Here is some code that illustrates this whole process, including the\n",
    "use of the penalty on weight magnitudes controlled by $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X, T, lamb=0):\n",
    "    means = X.mean(0)\n",
    "    stds = X.std(0)\n",
    "    n,d = X.shape\n",
    "    Xs1 = np.insert((X - means)/stds, 0, 1, axis=1)\n",
    "    lambDiag = np.eye(d+1) * lamb\n",
    "    lambDiag[0, 0] = 0\n",
    "    w = np.linalg.lstsq( Xs1.T @ Xs1 + lambDiag, Xs1.T @ T)[0]\n",
    "    return {'w': w, 'means':means, 'stds':stds, 'lambda': lamb}\n",
    "\n",
    "def use(model, X):\n",
    "    Xs1 = np.insert((X-model['means'])/model['stds'], 0, 1, axis=1)\n",
    "    return Xs1 @ model['w']\n",
    "\n",
    "def rmse(A,B):\n",
    "    return np.sqrt(np.mean( (A-B)**2 ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, make a simple function of $x$. How about $f(x) = -1 + 0.1 x^2 - 0.02 x^3 + 0.5 n$, where $n$ is from a standard Normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nSamples = 40\n",
    "trainingFraction = 0.5\n",
    "nModels = 1000\n",
    "confidence = 90 # percent\n",
    "lambdaw = 0.0 # penalty on weight magnitudes\n",
    "\n",
    "X = np.hstack((np.linspace(0, 3, num=nSamples),\n",
    "               np.linspace(6, 10, num=nSamples))).reshape((2*nSamples, 1))\n",
    "# T = -1 + 1 * X + 2 * np.sin(X*2) + 0.55*np.random.normal(size=(2*nSamples,1))\n",
    "T = -1 + 0 * X + 0.1 * X**2 - 0.02 * X**3 + 0.5*np.random.normal(size=(2*nSamples, 1))\n",
    "X.shape, T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X,T,'.-');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add squared and cubed values of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xf = np.hstack((X, X**2, X**3, X**4, X**5))\n",
    "#Xf = np.hstack((X, np.sin(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide data into training and testing sets, randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(7.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nRows = Xf.shape[0]\n",
    "rowIndices = np.arange(nRows)\n",
    "np.random.shuffle(rowIndices)\n",
    "nTrain = round(nRows*trainingFraction)\n",
    "nTest = nRows - nTrain\n",
    "trainI = rowIndices[:nTrain]\n",
    "testI = rowIndices[nTrain:]\n",
    "\n",
    "Xtrain = Xf[trainI,:]\n",
    "Ttrain = T[trainI,:]\n",
    "Xtest = Xf[testI,:]\n",
    "Ttest = T[testI,:]\n",
    "\n",
    "Xtrain.shape, Ttrain.shape, Xtest.shape, Ttest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Xtrain[:, 0], Ttrain, 'o', label='Train')\n",
    "plt.plot(Xtest[:, 0], Ttest, 'ro', label='Test')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make models based on bootstrap samples of training data.  *models* will be list of models, one for each bootstrap sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[random.randint(0,10) for i in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nModels = 100\n",
    "models = []\n",
    "for modeli in range(nModels):\n",
    "    # Draw random sample (row) numbers, with repetition\n",
    "    trainI = [random.randint(0, nTrain-1) for i in range(nTrain)]\n",
    "    XtrainBoot = Xtrain[trainI, :]\n",
    "    TtrainBoot = Ttrain[trainI, :]\n",
    "    model = train(XtrainBoot, TtrainBoot, 0)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will apply all of the models to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YAll = []\n",
    "for model in models:\n",
    "    YAll.append( use(model, Xtest) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(YAll).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(YAll).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YAll = np.array(YAll).squeeze().T \n",
    "Ytest = np.mean(YAll,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSEtest = np.sqrt(np.mean((Ytest - Ttest)**2))\n",
    "print('Test RMSE is {:.4f}'.format(RMSEtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nPlot = 100\n",
    "Xplot = np.linspace(0, 12.5, nPlot).reshape((nPlot ,1))\n",
    "Xplotf = np.hstack((Xplot, Xplot**2, Xplot**3, Xplot**4, Xplot**5))\n",
    "Ys = []\n",
    "for model in models:\n",
    "    Yplot = use(model, Xplotf)\n",
    "    Ys.append( Yplot.flatten())\n",
    "Ys = np.array(Ys).T\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(Xtrain[:, 0], Ttrain, 'o')\n",
    "plt.plot(Xtest[:, 0], Ttest, 'o')\n",
    "plt.plot(Xplotf[:, 0], Ys, alpha=0.2);\n",
    "plt.ylim(-14,2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now let's try some other data.  Here is some data related to the design of hulls on yachts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -O https://archive.ics.uci.edu/ml/machine-learning-databases/00243/yacht_hydrodynamics.data\n",
    "!head yacht_hydrodynamics.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('yacht_hydrodynamics.data')\n",
    "\n",
    "T = data[:,-1:]\n",
    "X = data[:,:-1]\n",
    "Xnames = ['Center of Buoyancy', 'Prismatic coefficient', 'Length-displacement ratio', 'Beam-draught ratio',\n",
    "          'Length-beam ratio', 'Froude number']\n",
    "Tname = 'Resistance'\n",
    "X.shape, T.shape, Xnames, Tname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.plot(X[:, i] ,T, '.')\n",
    "    plt.ylabel(Tname)\n",
    "    plt.xlabel(Xnames[i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[:100, :])\n",
    "plt.plot(T[:100, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(X, T)\n",
    "predict = use(model, X)\n",
    "print(rmse(predict, T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(T)\n",
    "plt.plot(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(T, predict, 'o')\n",
    "plt.plot([0, 50], [0, 50],  'r-')\n",
    "plt.xlabel('actual')\n",
    "plt.ylabel('predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Humm...that last variable, the Froude number, looks like its square root might be more linearly related to resistance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[:,-1], T, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[:,-1]**2, T, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[:,-1]**4, T, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[:,-1]**8, T, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xf = np.hstack([X, X[:,-1:]**8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(Xf, T)\n",
    "predict = use(model, Xf)\n",
    "print(rmse(predict, T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(T)\n",
    "plt.plot(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(T, predict, 'o')\n",
    "plt.plot([0, 50], [0, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "plt.plot(T[:n])\n",
    "plt.plot(predict[:n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe higher powers would work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for deg in range(1, 20):\n",
    "    Xf = X # .copy()\n",
    "    for d in range(2, deg+1):\n",
    "        Xf = np.hstack((Xf, X**d))\n",
    "    err = rmse( use( train(Xf, T), Xf), T)\n",
    "    #print(deg, Xf.shape)\n",
    "    result.append([deg,err])\n",
    "result = np.array(result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result[:,0],result[:,1],'o-')\n",
    "plt.xlabel('Exponent of X')\n",
    "plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf = np.hstack([X, X**2, X**3, X**4, X**5, X**6])\n",
    "predict = use(train(Xf, T), Xf)\n",
    "\n",
    "plt.plot(T)\n",
    "plt.plot(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(T, predict, 'o')\n",
    "plt.plot([0, 50], [0, 50])\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
